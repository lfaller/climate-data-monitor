# Production Configuration for Climate Data Monitor
# Configure your AWS S3 bucket and Quilt registry details here

climate:
  # URL or path to climate data source
  # Use file:// prefix for local files
  # For NOAA data: https://www.ncei.noaa.gov/data/... (future enhancement)
  source_url: "file://data/sample_climate_data.csv"

  # API key for remote data sources (if needed)
  api_key: null

  # Directory to store downloaded/processed data
  download_dir: "data/downloads"

  # Dataset identifier
  dataset_id: "GHCN_D"

  # Geographic scope for data (informational)
  geographic_scope: "production"

filtering:
  # Enable filtering of data
  enabled: false

  # Optional: Filter to specific station IDs
  # Example: ["USC00014821", "USC00023182"]
  station_ids: null

  # Optional: Filter to specific element types
  # Example: ["TMAX", "TMIN", "PRCP"]
  data_types: null

quality:
  thresholds:
    # Minimum acceptable quality score (0-100)
    min_quality_score: 75

    # Maximum percentage of null values allowed
    max_null_percentage: 15

    # Maximum percentage of outliers allowed
    max_outlier_percentage: 5

    # Maximum drift percentage between versions
    max_drift_percentage: 20

    # Temperature outlier detection (standard deviations)
    temp_outlier_std_dev: 3

    # Valid temperature range (Celsius)
    temp_min_valid: -60
    temp_max_valid: 60

    # Maximum daily precipitation (mm)
    precip_max_daily: 500

    # Precipitation outlier detection (standard deviations)
    precip_outlier_std_dev: 4

  # Directory for quality report output
  output_dir: "output/quality_reports"

quilt:
  # S3 bucket name for Quilt registry
  # REQUIRED: Update this to your AWS S3 bucket
  bucket: "your-climate-data-bucket"

  # Package name (namespace/name format)
  # Example: "climate-monitor/ghcn-daily"
  package_name: "climate/data"

  # Full S3 registry URL
  # Must match your bucket
  registry: "s3://your-climate-data-bucket"

  # Enable pushing to S3 registry
  # Set to false for local testing
  push_to_registry: true

  # AWS region for S3 bucket
  region: "us-west-2"

aws:
  # AWS region
  region: "us-west-2"

  # Validate AWS credentials before pushing
  validate_credentials: true

  # Test bucket access before pipeline runs
  test_bucket_access: true

alerts:
  # Enable alerting on quality issues
  enabled: false

  # Email address for alerts
  email: null

  # Slack webhook URL for notifications
  slack_webhook: null

scheduling:
  # Check interval in days (for future automation)
  check_interval_days: 30

  # Auto-run pipeline on schedule
  auto_run: false

logging:
  # Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
  level: "INFO"

  # Directory for log files
  log_dir: "logs"

  # Enable file logging
  file_logging: true

  # Enable console logging
  console_logging: true

# AWS Credentials (optional - recommended to use environment variables instead)
# AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables are preferred
# Or use AWS credential profiles: AWS_PROFILE=your-profile-name
